{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## << 문제 정의 >>\n",
        "\n",
        "글로벌 쇼핑몰의 클릭 로그 데이터를 분석하여, 어떤 유저가 어떤 아이템을 클릭하는지 확인하고 싶습니다.\n",
        "주어진 데이터는 해당 쇼핑몰의 2024년 4월 1일부터 2024년 5월 7일까지의 클릭 로그 데이터입니다.\n",
        "\n",
        "2024년 4월 1일부터 4월 30일까지의 데이터를 학습하여, 그 이후 일주일간 각 아이템을 클릭하는지 안하는지를 예측하는 문제를 풀어보세요.\n",
        "\n",
        "자세한 대회 관련 사항은 아래 대회 페이지를 참조하세요.\n",
        "\n",
        "[Competition Page]"
      ],
      "metadata": {
        "id": "TO2sC_QBVRvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
        "\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "seed_everything(42)  # 무조건 42로 세팅!!\n",
        "\n",
        "#파일 불러오기\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "submission = pd.read_csv('sample_submission.csv')\n"
      ],
      "metadata": {
        "id": "CgwXmKE_7I9t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train 데이터 튜닝\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "train = train.drop('click_id', axis=1)\n",
        "\n",
        "train = train.drop(['country'], axis=1)\n",
        "\n",
        "bins = [-float('inf'), 20, 100, 1000, float('inf')]\n",
        "labels = [0, 1, 2, 3]\n",
        "train['price_category'] = pd.cut(train['price'], bins=bins, labels=labels, include_lowest=True).astype(int)\n",
        "\n",
        "\n",
        "train['date'] = pd.to_datetime(train['date'])\n",
        "train['weekday'] = train['date'].dt.weekday\n",
        "train['is_weekend'] = train['weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
        "train = train.drop('date', axis=1)\n",
        "\n",
        "\n",
        "def fill_page1_from_page2(row):\n",
        "  if pd.isna(row['page 1 (main category)']) and pd.notna(row['page 2 (clothing model)']) and row['page 2 (clothing model)'] != '':\n",
        "        first_char = row['page 2 (clothing model)'][0].upper()\n",
        "        if first_char == 'A':\n",
        "            return 1.0\n",
        "        elif first_char == 'B':\n",
        "            return 2.0\n",
        "        elif first_char == 'C':\n",
        "            return 3.0\n",
        "        elif first_char == 'P':\n",
        "            return 4.0\n",
        "  return row['page 1 (main category)']\n",
        "\n",
        "train['page 1 (main category)'] = train.apply(fill_page1_from_page2, axis=1)\n",
        "\n",
        "ordinal_enc = OrdinalEncoder(categories=[[1.0, 2.0, 3.0, 4.0]])\n",
        "train['page_1_encoded'] = ordinal_enc.fit_transform(train[['page 1 (main category)']])\n",
        "\n",
        "train['page 2 (clothing model)'] = train['page 2 (clothing model)'].fillna('missing')  # NaN을 'missing'으로 변환\n",
        "train['page 2 (clothing model)'] = train['page 2 (clothing model)'].replace('', 'missing')  # 빈 문자열을 'missing'으로 변환\n",
        "target_enc = train.groupby('page 2 (clothing model)')['Clicked'].mean()\n",
        "train['page_2_encoded'] = train['page 2 (clothing model)'].map(target_enc)\n",
        "\n",
        "# page_2_encoded 결측치 채우기\n",
        "# 1. page 1 (main category)별 page 2 (clothing model)의 최빈값 계산\n",
        "mode_map = train.groupby('page 1 (main category)')['page 2 (clothing model)'].agg(lambda x: x.mode()[0] if not x.mode().empty else 'missing')\n",
        "# 2. 최빈값에 대응하는 page_2_encoded 값 매핑\n",
        "page_2_encoded_map = train.groupby('page 2 (clothing model)')['page_2_encoded'].mean()\n",
        "mode_encoded_map = mode_map.map(page_2_encoded_map)\n",
        "# 3. 기본값 설정 (page_2_encoded_map에 'missing'이 없으면 전체 평균 사용)\n",
        "default_value = train['Clicked'].mean() if 'missing' not in page_2_encoded_map else page_2_encoded_map['missing']\n",
        "# 4. 결측치 채우기 함수\n",
        "def fill_page_2_encoded(row):\n",
        "    if pd.isna(row['page_2_encoded']):\n",
        "        return mode_encoded_map.get(row['page 1 (main category)'], default_value)\n",
        "    return row['page_2_encoded']\n",
        "\n",
        "train['page_2_encoded'] = train.apply(fill_page_2_encoded, axis=1)\n",
        "\n",
        "bins = [-float('inf'), 3, float('inf')]\n",
        "labels = [1, 2]\n",
        "train['location'] = pd.cut(train['location'], bins=bins, labels=labels, include_lowest=True).astype(int)\n",
        "\n",
        "bins = [-float('inf'), 0, 3, 5, float('inf')]\n",
        "labels = [0, 1, 2, 3]\n",
        "train['page'] = pd.cut(train['page'], bins=bins, labels=labels, include_lowest=True).astype(int)\n",
        "\n",
        "bins = [-float('inf'), 2, 6, float('inf')]\n",
        "labels = [0, 1, 2]\n",
        "train['order'] = pd.cut(train['order'], bins=bins, labels=labels, include_lowest=True).astype(int)\n",
        "\n",
        "train = train.drop(['session ID'], axis=1)\n",
        "\n",
        "\n",
        "onehot_enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "onehot_cols = onehot_enc.fit_transform(train[['model photography']])\n",
        "onehot_col_names = onehot_enc.get_feature_names_out(['model photography'])\n",
        "onehot_df = pd.DataFrame(onehot_cols, columns=onehot_col_names)\n",
        "train = pd.concat([train, onehot_df], axis=1)\n",
        "\n",
        "train = train.drop(['price', 'page 1 (main category)', 'page 2 (clothing model)', 'model photography'], axis=1)\n"
      ],
      "metadata": {
        "id": "V_bBSHbQ8KA-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop('Clicked', axis=1)\n",
        "y = train['Clicked']\n",
        "\n",
        "# 훈련/검증 데이터 분리\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "OQvrJp4PBpiE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut2mEfTb8KFF",
        "outputId": "987b2a1d-15e0-429b-d10f-903b70f70347"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    # 탐색할 하이퍼파라미터 정의\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 4, 40),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'objective': 'binary:logistic',\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    # XGBoost 모델 생성 및 학습\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 검증 데이터로 예측 및 정확도 계산\n",
        "    y_pred = model.predict(X_val)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Optuna 스터디 생성 및 최적화\n",
        "study = optuna.create_study(direction='maximize')  # 정확도를 최대화\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(\"최적의 파라미터:\", study.best_params)\n",
        "print(\"최고 정확도:\", study.best_value)\n",
        "\n",
        "best_params = study.best_params\n",
        "XGb = XGBClassifier(**best_params, objective='binary:logistic', random_state=42)\n",
        "XGb.fit(X_train, y_train)\n",
        "\n",
        "train_pred = XGb.predict(X_train)\n",
        "val_pred = XGb.predict(X_val)\n",
        "\n",
        "\n",
        "# 학습한 모델을 평가\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Train ACC : %.4f\" % accuracy_score(y_train, train_pred))\n",
        "print(\"Val ACC : %.4f\" % accuracy_score(y_val, val_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3lrm7HU8KKS",
        "outputId": "822c5355-1762-4700-f612-2122c8ef6f98"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-26 13:41:26,913] A new study created in memory with name: no-name-788afd08-777b-400f-a153-6e34bda49468\n",
            "[I 2025-03-26 13:41:39,716] Trial 0 finished with value: 0.649896265560166 and parameters: {'max_depth': 39, 'learning_rate': 0.09928189340299635, 'n_estimators': 115, 'subsample': 0.7765630756052073, 'colsample_bytree': 0.6697668951144122}. Best is trial 0 with value: 0.649896265560166.\n",
            "[I 2025-03-26 13:41:50,472] Trial 1 finished with value: 0.6684647302904564 and parameters: {'max_depth': 6, 'learning_rate': 0.24728322899573799, 'n_estimators': 251, 'subsample': 0.5440678429850238, 'colsample_bytree': 0.7188657540018195}. Best is trial 1 with value: 0.6684647302904564.\n",
            "[I 2025-03-26 13:42:06,660] Trial 2 finished with value: 0.645746887966805 and parameters: {'max_depth': 22, 'learning_rate': 0.1963079932775404, 'n_estimators': 228, 'subsample': 0.9725472420315964, 'colsample_bytree': 0.6024094449141035}. Best is trial 1 with value: 0.6684647302904564.\n",
            "[I 2025-03-26 13:42:08,787] Trial 3 finished with value: 0.6459543568464731 and parameters: {'max_depth': 30, 'learning_rate': 0.13408693803965221, 'n_estimators': 143, 'subsample': 0.7555275956324521, 'colsample_bytree': 0.7968292587720692}. Best is trial 1 with value: 0.6684647302904564.\n",
            "[I 2025-03-26 13:42:10,345] Trial 4 finished with value: 0.6556016597510373 and parameters: {'max_depth': 17, 'learning_rate': 0.07104922574712727, 'n_estimators': 137, 'subsample': 0.5783557374401089, 'colsample_bytree': 0.6466622013059566}. Best is trial 1 with value: 0.6684647302904564.\n",
            "[I 2025-03-26 13:42:13,459] Trial 5 finished with value: 0.6462655601659751 and parameters: {'max_depth': 32, 'learning_rate': 0.29569475717716087, 'n_estimators': 111, 'subsample': 0.8149125582358545, 'colsample_bytree': 0.5463379577832477}. Best is trial 1 with value: 0.6684647302904564.\n",
            "[I 2025-03-26 13:42:15,225] Trial 6 finished with value: 0.6551867219917012 and parameters: {'max_depth': 31, 'learning_rate': 0.07278998894444805, 'n_estimators': 163, 'subsample': 0.8120126480187514, 'colsample_bytree': 0.5641837121708071}. Best is trial 1 with value: 0.6684647302904564.\n",
            "[I 2025-03-26 13:42:19,024] Trial 7 finished with value: 0.645746887966805 and parameters: {'max_depth': 38, 'learning_rate': 0.15721858815596812, 'n_estimators': 254, 'subsample': 0.6925551757416384, 'colsample_bytree': 0.7467035280382044}. Best is trial 1 with value: 0.6684647302904564.\n",
            "[I 2025-03-26 13:42:22,113] Trial 8 finished with value: 0.6461618257261411 and parameters: {'max_depth': 35, 'learning_rate': 0.13579535040843904, 'n_estimators': 299, 'subsample': 0.5024351416143088, 'colsample_bytree': 0.572592332491566}. Best is trial 1 with value: 0.6684647302904564.\n",
            "[I 2025-03-26 13:42:23,619] Trial 9 finished with value: 0.6719917012448133 and parameters: {'max_depth': 13, 'learning_rate': 0.013569699066286543, 'n_estimators': 136, 'subsample': 0.8217874728631207, 'colsample_bytree': 0.62894068665083}. Best is trial 9 with value: 0.6719917012448133.\n",
            "[I 2025-03-26 13:42:25,324] Trial 10 finished with value: 0.6718879668049793 and parameters: {'max_depth': 8, 'learning_rate': 0.02055571634400586, 'n_estimators': 50, 'subsample': 0.9379006558351661, 'colsample_bytree': 0.987828617325476}. Best is trial 9 with value: 0.6719917012448133.\n",
            "[I 2025-03-26 13:42:25,841] Trial 11 finished with value: 0.6724066390041494 and parameters: {'max_depth': 8, 'learning_rate': 0.023070233126797252, 'n_estimators': 51, 'subsample': 0.9471084430356529, 'colsample_bytree': 0.9875473489264589}. Best is trial 11 with value: 0.6724066390041494.\n",
            "[I 2025-03-26 13:42:26,497] Trial 12 finished with value: 0.6616182572614108 and parameters: {'max_depth': 13, 'learning_rate': 0.014442829855181529, 'n_estimators': 51, 'subsample': 0.8994584089768357, 'colsample_bytree': 0.9019174298251598}. Best is trial 11 with value: 0.6724066390041494.\n",
            "[I 2025-03-26 13:42:27,458] Trial 13 finished with value: 0.6629668049792531 and parameters: {'max_depth': 12, 'learning_rate': 0.04671285786599818, 'n_estimators': 87, 'subsample': 0.8802537690453529, 'colsample_bytree': 0.8415602881823938}. Best is trial 11 with value: 0.6724066390041494.\n",
            "[I 2025-03-26 13:42:31,462] Trial 14 finished with value: 0.6565352697095436 and parameters: {'max_depth': 20, 'learning_rate': 0.01370245378663207, 'n_estimators': 214, 'subsample': 0.670180400346057, 'colsample_bytree': 0.9846320340573931}. Best is trial 11 with value: 0.6724066390041494.\n",
            "[I 2025-03-26 13:42:32,041] Trial 15 finished with value: 0.6798755186721992 and parameters: {'max_depth': 4, 'learning_rate': 0.09160140288325722, 'n_estimators': 187, 'subsample': 0.9986667130156572, 'colsample_bytree': 0.8863036320035608}. Best is trial 15 with value: 0.6798755186721992.\n",
            "[I 2025-03-26 13:42:32,673] Trial 16 finished with value: 0.6773858921161826 and parameters: {'max_depth': 5, 'learning_rate': 0.10117394813628086, 'n_estimators': 190, 'subsample': 0.9676082009189068, 'colsample_bytree': 0.9085641409350329}. Best is trial 15 with value: 0.6798755186721992.\n",
            "[I 2025-03-26 13:42:33,264] Trial 17 finished with value: 0.6826763485477179 and parameters: {'max_depth': 4, 'learning_rate': 0.10338218172422212, 'n_estimators': 197, 'subsample': 0.9986263986354484, 'colsample_bytree': 0.9142986176322235}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:42:38,923] Trial 18 finished with value: 0.6424273858921162 and parameters: {'max_depth': 27, 'learning_rate': 0.1754249757952097, 'n_estimators': 186, 'subsample': 0.9983358414239522, 'colsample_bytree': 0.8920599111689336}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:42:39,584] Trial 19 finished with value: 0.6770746887966805 and parameters: {'max_depth': 4, 'learning_rate': 0.2174482470065116, 'n_estimators': 214, 'subsample': 0.8961651562105425, 'colsample_bytree': 0.8340513114924684}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:42:40,884] Trial 20 finished with value: 0.6558091286307054 and parameters: {'max_depth': 10, 'learning_rate': 0.10256541301119604, 'n_estimators': 168, 'subsample': 0.6686675960628109, 'colsample_bytree': 0.9230727506307929}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:42:41,474] Trial 21 finished with value: 0.6820539419087137 and parameters: {'max_depth': 4, 'learning_rate': 0.10680882820518577, 'n_estimators': 195, 'subsample': 0.9972022021912339, 'colsample_bytree': 0.9266759206780927}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:42:44,472] Trial 22 finished with value: 0.6463692946058092 and parameters: {'max_depth': 16, 'learning_rate': 0.1254650981654318, 'n_estimators': 190, 'subsample': 0.9953569715889348, 'colsample_bytree': 0.9428132481438614}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:42:45,140] Trial 23 finished with value: 0.6806016597510374 and parameters: {'max_depth': 4, 'learning_rate': 0.07003810272551453, 'n_estimators': 228, 'subsample': 0.9234153580810679, 'colsample_bytree': 0.8452964642778605}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:42:46,780] Trial 24 finished with value: 0.6599585062240664 and parameters: {'max_depth': 9, 'learning_rate': 0.05771459768910124, 'n_estimators': 263, 'subsample': 0.9209916642231964, 'colsample_bytree': 0.8397155642741485}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:42:47,811] Trial 25 finished with value: 0.6675311203319502 and parameters: {'max_depth': 7, 'learning_rate': 0.12033450280972356, 'n_estimators': 228, 'subsample': 0.8585008728499803, 'colsample_bytree': 0.7930517127307719}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:42:54,276] Trial 26 finished with value: 0.6441908713692946 and parameters: {'max_depth': 16, 'learning_rate': 0.046310909848151255, 'n_estimators': 271, 'subsample': 0.9343565096143897, 'colsample_bytree': 0.9487462886851112}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:42:56,151] Trial 27 finished with value: 0.6452282157676349 and parameters: {'max_depth': 11, 'learning_rate': 0.15833130441882742, 'n_estimators': 208, 'subsample': 0.8698373360808711, 'colsample_bytree': 0.8581454624292683}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:42:56,881] Trial 28 finished with value: 0.6797717842323652 and parameters: {'max_depth': 4, 'learning_rate': 0.07809144026811829, 'n_estimators': 236, 'subsample': 0.9518610809416569, 'colsample_bytree': 0.8019795183603833}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:43:07,946] Trial 29 finished with value: 0.6512448132780083 and parameters: {'max_depth': 14, 'learning_rate': 0.10939445108349445, 'n_estimators': 155, 'subsample': 0.7187944810463527, 'colsample_bytree': 0.6848617219353854}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:43:16,663] Trial 30 finished with value: 0.6453319502074689 and parameters: {'max_depth': 23, 'learning_rate': 0.08271888049209027, 'n_estimators': 289, 'subsample': 0.8398722086942325, 'colsample_bytree': 0.8752673728462823}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:43:17,429] Trial 31 finished with value: 0.6753112033195021 and parameters: {'max_depth': 6, 'learning_rate': 0.0890711095951361, 'n_estimators': 197, 'subsample': 0.9895522902577905, 'colsample_bytree': 0.9447702172751578}. Best is trial 17 with value: 0.6826763485477179.\n",
            "[I 2025-03-26 13:43:18,011] Trial 32 finished with value: 0.683402489626556 and parameters: {'max_depth': 4, 'learning_rate': 0.04111189211906206, 'n_estimators': 179, 'subsample': 0.914720176898157, 'colsample_bytree': 0.8720247709344804}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:19,108] Trial 33 finished with value: 0.6766597510373444 and parameters: {'max_depth': 7, 'learning_rate': 0.03954510950536097, 'n_estimators': 239, 'subsample': 0.9122170541101214, 'colsample_bytree': 0.7617102994476375}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:20,133] Trial 34 finished with value: 0.6718879668049793 and parameters: {'max_depth': 10, 'learning_rate': 0.06244479376604846, 'n_estimators': 174, 'subsample': 0.9663068126347258, 'colsample_bytree': 0.5084557035142705}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:21,091] Trial 35 finished with value: 0.6652489626556016 and parameters: {'max_depth': 7, 'learning_rate': 0.14409673798694203, 'n_estimators': 206, 'subsample': 0.7793541846817484, 'colsample_bytree': 0.8189607654156158}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:21,582] Trial 36 finished with value: 0.678941908713693 and parameters: {'max_depth': 4, 'learning_rate': 0.11335060790938739, 'n_estimators': 150, 'subsample': 0.6093858188121163, 'colsample_bytree': 0.8644070573928079}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:22,143] Trial 37 finished with value: 0.6803941908713693 and parameters: {'max_depth': 6, 'learning_rate': 0.032287210623964384, 'n_estimators': 117, 'subsample': 0.9658089490095002, 'colsample_bytree': 0.9336368924808294}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:27,105] Trial 38 finished with value: 0.645643153526971 and parameters: {'max_depth': 20, 'learning_rate': 0.06662600082586838, 'n_estimators': 220, 'subsample': 0.9258627560955963, 'colsample_bytree': 0.9619165073206843}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:30,024] Trial 39 finished with value: 0.6479253112033195 and parameters: {'max_depth': 9, 'learning_rate': 0.28154462690447235, 'n_estimators': 241, 'subsample': 0.7842599437435149, 'colsample_bytree': 0.7657118621557754}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:32,384] Trial 40 finished with value: 0.6428423236514523 and parameters: {'max_depth': 28, 'learning_rate': 0.17468788741578972, 'n_estimators': 176, 'subsample': 0.8463417575765125, 'colsample_bytree': 0.7070813770060116}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:32,950] Trial 41 finished with value: 0.6802904564315353 and parameters: {'max_depth': 6, 'learning_rate': 0.03461581694812617, 'n_estimators': 129, 'subsample': 0.9582678796687503, 'colsample_bytree': 0.9147701346296813}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:33,766] Trial 42 finished with value: 0.6772821576763486 and parameters: {'max_depth': 6, 'learning_rate': 0.059131063558893235, 'n_estimators': 201, 'subsample': 0.9691724745891744, 'colsample_bytree': 0.930460856995054}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:34,153] Trial 43 finished with value: 0.6821576763485477 and parameters: {'max_depth': 4, 'learning_rate': 0.039289633867266555, 'n_estimators': 104, 'subsample': 0.8906841448786816, 'colsample_bytree': 0.9652651856041492}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:34,719] Trial 44 finished with value: 0.6743775933609959 and parameters: {'max_depth': 8, 'learning_rate': 0.05438194034361063, 'n_estimators': 88, 'subsample': 0.8943742957387099, 'colsample_bytree': 0.9707192154297064}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:35,653] Trial 45 finished with value: 0.6828838174273859 and parameters: {'max_depth': 4, 'learning_rate': 0.07423365965716608, 'n_estimators': 161, 'subsample': 0.9386759898778987, 'colsample_bytree': 0.9955532274247487}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:37,000] Trial 46 finished with value: 0.6561203319502075 and parameters: {'max_depth': 11, 'learning_rate': 0.09317780022143088, 'n_estimators': 96, 'subsample': 0.8824584234837994, 'colsample_bytree': 0.9949944635745498}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:37,885] Trial 47 finished with value: 0.666701244813278 and parameters: {'max_depth': 9, 'learning_rate': 0.14155759623127664, 'n_estimators': 65, 'subsample': 0.977228895909425, 'colsample_bytree': 0.9675916763344695}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:41,884] Trial 48 finished with value: 0.6437759336099586 and parameters: {'max_depth': 14, 'learning_rate': 0.07629769977660332, 'n_estimators': 158, 'subsample': 0.9406816533511537, 'colsample_bytree': 0.957944279521584}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:44,549] Trial 49 finished with value: 0.6547717842323652 and parameters: {'max_depth': 37, 'learning_rate': 0.024084874237304568, 'n_estimators': 144, 'subsample': 0.9100660585930649, 'colsample_bytree': 0.8984565666876432}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:45,044] Trial 50 finished with value: 0.6823651452282158 and parameters: {'max_depth': 5, 'learning_rate': 0.04660071135108242, 'n_estimators': 119, 'subsample': 0.8085933994228384, 'colsample_bytree': 0.9982128714521279}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:45,541] Trial 51 finished with value: 0.6799792531120332 and parameters: {'max_depth': 5, 'learning_rate': 0.04732011864681734, 'n_estimators': 122, 'subsample': 0.8055134067126679, 'colsample_bytree': 0.9954485749756193}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:46,033] Trial 52 finished with value: 0.6820539419087137 and parameters: {'max_depth': 5, 'learning_rate': 0.030207693925238574, 'n_estimators': 109, 'subsample': 0.7448162446185245, 'colsample_bytree': 0.9782227751804639}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:46,660] Trial 53 finished with value: 0.6693983402489626 and parameters: {'max_depth': 8, 'learning_rate': 0.07908486846295316, 'n_estimators': 106, 'subsample': 0.8321831383426961, 'colsample_bytree': 0.9191511594296506}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:46,973] Trial 54 finished with value: 0.6820539419087137 and parameters: {'max_depth': 4, 'learning_rate': 0.12664090962236454, 'n_estimators': 72, 'subsample': 0.8677734268843137, 'colsample_bytree': 0.9721816161023611}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:49,951] Trial 55 finished with value: 0.6463692946058092 and parameters: {'max_depth': 40, 'learning_rate': 0.043125170035924164, 'n_estimators': 134, 'subsample': 0.9487476650029464, 'colsample_bytree': 0.9981445641672716}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:50,651] Trial 56 finished with value: 0.6758298755186722 and parameters: {'max_depth': 6, 'learning_rate': 0.09869273765067346, 'n_estimators': 181, 'subsample': 0.9809124308708381, 'colsample_bytree': 0.8813056210777341}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:51,553] Trial 57 finished with value: 0.6767634854771785 and parameters: {'max_depth': 7, 'learning_rate': 0.010983392657410725, 'n_estimators': 166, 'subsample': 0.8069834182622342, 'colsample_bytree': 0.9501177072248436}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:53,589] Trial 58 finished with value: 0.6787344398340249 and parameters: {'max_depth': 5, 'learning_rate': 0.07005572586953249, 'n_estimators': 144, 'subsample': 0.8895146276864189, 'colsample_bytree': 0.9111423275898711}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:56,182] Trial 59 finished with value: 0.6475103734439834 and parameters: {'max_depth': 34, 'learning_rate': 0.048812849047611864, 'n_estimators': 100, 'subsample': 0.9333136418449046, 'colsample_bytree': 0.9327087916260242}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:58,132] Trial 60 finished with value: 0.6621369294605809 and parameters: {'max_depth': 12, 'learning_rate': 0.022716911929129214, 'n_estimators': 168, 'subsample': 0.8565733893575063, 'colsample_bytree': 0.9745886699634667}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:58,673] Trial 61 finished with value: 0.6812240663900415 and parameters: {'max_depth': 5, 'learning_rate': 0.026502593646916865, 'n_estimators': 124, 'subsample': 0.7461913177140869, 'colsample_bytree': 0.9773495937208172}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:59,000] Trial 62 finished with value: 0.6817427385892116 and parameters: {'max_depth': 4, 'learning_rate': 0.03181214128051397, 'n_estimators': 77, 'subsample': 0.7456381079164218, 'colsample_bytree': 0.9551905715895691}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:43:59,609] Trial 63 finished with value: 0.6751037344398341 and parameters: {'max_depth': 7, 'learning_rate': 0.05404750887286326, 'n_estimators': 109, 'subsample': 0.6733266579929152, 'colsample_bytree': 0.9998187509032013}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:00,949] Trial 64 finished with value: 0.6688796680497925 and parameters: {'max_depth': 9, 'learning_rate': 0.037637102352554054, 'n_estimators': 198, 'subsample': 0.7233525991923673, 'colsample_bytree': 0.8997919630801847}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:01,268] Trial 65 finished with value: 0.6827800829875519 and parameters: {'max_depth': 4, 'learning_rate': 0.08358119496034666, 'n_estimators': 88, 'subsample': 0.9091783040422702, 'colsample_bytree': 0.9401697637780544}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:01,610] Trial 66 finished with value: 0.6812240663900415 and parameters: {'max_depth': 4, 'learning_rate': 0.10632472258188512, 'n_estimators': 92, 'subsample': 0.9139073517118195, 'colsample_bytree': 0.9340982089780747}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:03,237] Trial 67 finished with value: 0.6476141078838175 and parameters: {'max_depth': 24, 'learning_rate': 0.08671938479673574, 'n_estimators': 84, 'subsample': 0.9844489001892566, 'colsample_bytree': 0.8625949862920224}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:05,759] Trial 68 finished with value: 0.6530082987551867 and parameters: {'max_depth': 10, 'learning_rate': 0.2286025629194892, 'n_estimators': 189, 'subsample': 0.9963687816930024, 'colsample_bytree': 0.639625848002144}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:06,782] Trial 69 finished with value: 0.6727178423236515 and parameters: {'max_depth': 7, 'learning_rate': 0.11685473820683744, 'n_estimators': 101, 'subsample': 0.9036321880345357, 'colsample_bytree': 0.9469028099171053}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:07,516] Trial 70 finished with value: 0.6760373443983403 and parameters: {'max_depth': 5, 'learning_rate': 0.09444201960954075, 'n_estimators': 213, 'subsample': 0.9556604671128507, 'colsample_bytree': 0.9189095426687447}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:07,978] Trial 71 finished with value: 0.6798755186721992 and parameters: {'max_depth': 5, 'learning_rate': 0.06809729134447448, 'n_estimators': 109, 'subsample': 0.7153446082993214, 'colsample_bytree': 0.9796170783755426}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:08,333] Trial 72 finished with value: 0.6799792531120332 and parameters: {'max_depth': 6, 'learning_rate': 0.0567681981383083, 'n_estimators': 65, 'subsample': 0.7954682475248518, 'colsample_bytree': 0.9622732394579409}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:08,762] Trial 73 finished with value: 0.6808091286307054 and parameters: {'max_depth': 4, 'learning_rate': 0.08214263226338123, 'n_estimators': 116, 'subsample': 0.8281451217945554, 'colsample_bytree': 0.8852833386083119}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:09,790] Trial 74 finished with value: 0.6661825726141078 and parameters: {'max_depth': 8, 'learning_rate': 0.0646663907736345, 'n_estimators': 180, 'subsample': 0.760382687412627, 'colsample_bytree': 0.9838556076618954}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:10,327] Trial 75 finished with value: 0.6806016597510374 and parameters: {'max_depth': 5, 'learning_rate': 0.041289737855581495, 'n_estimators': 136, 'subsample': 0.8752199084794975, 'colsample_bytree': 0.9439092226378771}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:10,891] Trial 76 finished with value: 0.6740663900414938 and parameters: {'max_depth': 8, 'learning_rate': 0.019109696863541643, 'n_estimators': 80, 'subsample': 0.9292575413037794, 'colsample_bytree': 0.984900497287973}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:11,386] Trial 77 finished with value: 0.6806016597510374 and parameters: {'max_depth': 4, 'learning_rate': 0.12916631721748295, 'n_estimators': 158, 'subsample': 0.9451678924420883, 'colsample_bytree': 0.928180180965543}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:12,012] Trial 78 finished with value: 0.6787344398340249 and parameters: {'max_depth': 6, 'learning_rate': 0.03143716847451941, 'n_estimators': 128, 'subsample': 0.6251048807614731, 'colsample_bytree': 0.9645907859371374}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:13,180] Trial 79 finished with value: 0.6589211618257261 and parameters: {'max_depth': 10, 'learning_rate': 0.07295819673960631, 'n_estimators': 152, 'subsample': 0.7699394984480202, 'colsample_bytree': 0.9041961571794422}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:14,102] Trial 80 finished with value: 0.6779045643153527 and parameters: {'max_depth': 6, 'learning_rate': 0.04897804768488033, 'n_estimators': 222, 'subsample': 0.9999677071963857, 'colsample_bytree': 0.5926303536655169}. Best is trial 32 with value: 0.683402489626556.\n",
            "[I 2025-03-26 13:44:14,368] Trial 81 finished with value: 0.6838174273858921 and parameters: {'max_depth': 4, 'learning_rate': 0.12523623932550687, 'n_estimators': 67, 'subsample': 0.8545191210364028, 'colsample_bytree': 0.974846567452876}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:14,645] Trial 82 finished with value: 0.6796680497925311 and parameters: {'max_depth': 5, 'learning_rate': 0.11276092259594042, 'n_estimators': 60, 'subsample': 0.849793255981504, 'colsample_bytree': 0.9399436668669624}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:14,964] Trial 83 finished with value: 0.683195020746888 and parameters: {'max_depth': 4, 'learning_rate': 0.1006711199919843, 'n_estimators': 73, 'subsample': 0.8629240144041549, 'colsample_bytree': 0.9571288861562545}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:15,323] Trial 84 finished with value: 0.674585062240664 and parameters: {'max_depth': 7, 'learning_rate': 0.10292644473608667, 'n_estimators': 59, 'subsample': 0.519046002617835, 'colsample_bytree': 0.9550245934182883}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:15,606] Trial 85 finished with value: 0.6802904564315353 and parameters: {'max_depth': 4, 'learning_rate': 0.1380282686610516, 'n_estimators': 73, 'subsample': 0.891413330661332, 'colsample_bytree': 0.9869589208989064}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:20,873] Trial 86 finished with value: 0.6453319502074689 and parameters: {'max_depth': 19, 'learning_rate': 0.14807192195463853, 'n_estimators': 195, 'subsample': 0.86499304811126, 'colsample_bytree': 0.87158500236482}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:21,443] Trial 87 finished with value: 0.6688796680497925 and parameters: {'max_depth': 8, 'learning_rate': 0.12209811304984211, 'n_estimators': 93, 'subsample': 0.8406432928943639, 'colsample_bytree': 0.9209981714733656}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:21,685] Trial 88 finished with value: 0.6823651452282158 and parameters: {'max_depth': 4, 'learning_rate': 0.0879281219845734, 'n_estimators': 53, 'subsample': 0.8783823418617097, 'colsample_bytree': 0.8908046227832104}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:22,008] Trial 89 finished with value: 0.6760373443983403 and parameters: {'max_depth': 7, 'learning_rate': 0.0869716362279131, 'n_estimators': 53, 'subsample': 0.9003849932978194, 'colsample_bytree': 0.8937518257028272}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:22,294] Trial 90 finished with value: 0.6812240663900415 and parameters: {'max_depth': 4, 'learning_rate': 0.16430170577057684, 'n_estimators': 63, 'subsample': 0.8781222455019522, 'colsample_bytree': 0.8541100493416734}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:22,612] Trial 91 finished with value: 0.6808091286307054 and parameters: {'max_depth': 5, 'learning_rate': 0.10034384517398294, 'n_estimators': 70, 'subsample': 0.8210786487634998, 'colsample_bytree': 0.9609782578531045}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:22,997] Trial 92 finished with value: 0.6779045643153527 and parameters: {'max_depth': 6, 'learning_rate': 0.11143969470470211, 'n_estimators': 82, 'subsample': 0.9194445327233178, 'colsample_bytree': 0.9112767577746785}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:23,341] Trial 93 finished with value: 0.6798755186721992 and parameters: {'max_depth': 4, 'learning_rate': 0.13202907479505743, 'n_estimators': 87, 'subsample': 0.8563582387225828, 'colsample_bytree': 0.9341764899321019}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:23,627] Trial 94 finished with value: 0.6807053941908714 and parameters: {'max_depth': 6, 'learning_rate': 0.08941666363452483, 'n_estimators': 53, 'subsample': 0.882848274836975, 'colsample_bytree': 0.9484596758266304}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:24,360] Trial 95 finished with value: 0.679253112033195 and parameters: {'max_depth': 5, 'learning_rate': 0.07939761659356225, 'n_estimators': 207, 'subsample': 0.9594638368622465, 'colsample_bytree': 0.8191392829384738}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:24,648] Trial 96 finished with value: 0.6813278008298755 and parameters: {'max_depth': 4, 'learning_rate': 0.11936409203997346, 'n_estimators': 75, 'subsample': 0.9087509002629497, 'colsample_bytree': 0.7384997627306222}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:25,494] Trial 97 finished with value: 0.6681535269709543 and parameters: {'max_depth': 7, 'learning_rate': 0.09595111589559334, 'n_estimators': 183, 'subsample': 0.9745971719738609, 'colsample_bytree': 0.9692611478864153}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:25,945] Trial 98 finished with value: 0.6804979253112033 and parameters: {'max_depth': 5, 'learning_rate': 0.060067684108620345, 'n_estimators': 98, 'subsample': 0.8665102362466215, 'colsample_bytree': 0.9885341306066999}. Best is trial 81 with value: 0.6838174273858921.\n",
            "[I 2025-03-26 13:44:26,678] Trial 99 finished with value: 0.6738589211618258 and parameters: {'max_depth': 6, 'learning_rate': 0.10601981184150495, 'n_estimators': 175, 'subsample': 0.9234956559449892, 'colsample_bytree': 0.8778795565161048}. Best is trial 81 with value: 0.6838174273858921.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 파라미터: {'max_depth': 4, 'learning_rate': 0.12523623932550687, 'n_estimators': 67, 'subsample': 0.8545191210364028, 'colsample_bytree': 0.974846567452876}\n",
            "최고 정확도: 0.6838174273858921\n",
            "Train ACC : 0.6864\n",
            "Val ACC : 0.6838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
        "\n",
        "# test 데이터에서 click_id 제거\n",
        "test = test.drop('click_id', axis=1)\n",
        "\n",
        "test = test.drop(['country'], axis=1)\n",
        "\n",
        "# price_category 생성\n",
        "bins = [-float('inf'), 20, 100, 1000, float('inf')]\n",
        "labels = [0, 1, 2, 3]\n",
        "test['price_category'] = pd.cut(test['price'], bins=bins, labels=labels, include_lowest=True).astype(int)\n",
        "\n",
        "# date 관련 피처 생성\n",
        "test['date'] = pd.to_datetime(test['date'])\n",
        "test['weekday'] = test['date'].dt.weekday\n",
        "test['is_weekend'] = test['weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
        "test = test.drop('date', axis=1)\n",
        "\n",
        "# page 1 (main category) 결측치 채우기\n",
        "def fill_page1_from_page2(row):\n",
        "    if pd.isna(row['page 1 (main category)']) and pd.notna(row['page 2 (clothing model)']) and row['page 2 (clothing model)'] != '':\n",
        "        first_char = row['page 2 (clothing model)'][0].upper()\n",
        "        if first_char == 'A':\n",
        "            return 1.0\n",
        "        elif first_char == 'B':\n",
        "            return 2.0\n",
        "        elif first_char == 'C':\n",
        "            return 3.0\n",
        "        elif first_char == 'P':\n",
        "            return 4.0\n",
        "    return row['page 1 (main category)']\n",
        "\n",
        "test['page 1 (main category)'] = test.apply(fill_page1_from_page2, axis=1)\n",
        "\n",
        "# page_1_encoded 생성 (train에서 학습된 ordinal_enc 사용)\n",
        "test['page_1_encoded'] = ordinal_enc.transform(test[['page 1 (main category)']])\n",
        "\n",
        "# page_2_encoded 생성 (train에서 계산된 target_enc 사용)\n",
        "test['page 2 (clothing model)'] = test['page 2 (clothing model)'].fillna('missing')  # NaN을 'missing'으로 변환\n",
        "test['page 2 (clothing model)'] = test['page 2 (clothing model)'].replace('', 'missing')  # 빈 문자열을 'missing'으로 변환\n",
        "test['page_2_encoded'] = test['page 2 (clothing model)'].map(target_enc)\n",
        "\n",
        "# page_2_encoded 결측치 채우기 (train에서 계산된 mode_encoded_map과 default_value 사용)\n",
        "def fill_page_2_encoded(row):\n",
        "    if pd.isna(row['page_2_encoded']):\n",
        "        return mode_encoded_map.get(row['page 1 (main category)'], default_value)\n",
        "    return row['page_2_encoded']\n",
        "\n",
        "test['page_2_encoded'] = test.apply(fill_page_2_encoded, axis=1)\n",
        "\n",
        "test = test.drop(['session ID'], axis=1)\n",
        "\n",
        "bins = [-float('inf'), 3, float('inf')]\n",
        "labels = [1, 2]\n",
        "test['location'] = pd.cut(test['location'], bins=bins, labels=labels, include_lowest=True).astype(int)\n",
        "\n",
        "bins = [-float('inf'), 0, 3, 5, float('inf')]\n",
        "labels = [0, 1, 2, 3]\n",
        "test['page'] = pd.cut(test['page'], bins=bins, labels=labels, include_lowest=True).astype(int)\n",
        "\n",
        "bins = [-float('inf'), 2, 6, float('inf')]\n",
        "labels = [0, 1, 2]\n",
        "test['order'] = pd.cut(test['order'], bins=bins, labels=labels, include_lowest=True).astype(int)\n",
        "\n",
        "# One-Hot Encoding (train에서 학습된 onehot_enc 사용)\n",
        "onehot_cols = onehot_enc.transform(test[['model photography']])\n",
        "onehot_col_names = onehot_enc.get_feature_names_out(['model photography'])\n",
        "onehot_df = pd.DataFrame(onehot_cols, columns=onehot_col_names)\n",
        "test = pd.concat([test, onehot_df], axis=1)\n",
        "\n",
        "# 불필요한 열 제거\n",
        "test = test.drop(['price', 'page 1 (main category)', 'page 2 (clothing model)', 'model photography'], axis=1)"
      ],
      "metadata": {
        "id": "WHHX9I-S8chR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test\n",
        "\n",
        "output = XGb.predict(X_test)\n",
        "assert len(output) == 7695  # sanity check\n",
        "\n",
        "#파일 만들기\n",
        "\n",
        "submission = pd.read_csv('sample_submission.csv')\n",
        "submission['Clicked'] = output\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "mRjmxayL8jOa"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}